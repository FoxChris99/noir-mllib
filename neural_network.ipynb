{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/class_100k_10features_classification.csv\")\n",
    "target_name = \"Target\"\n",
    "y_train = df.pop(target_name)\n",
    "X_train = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/class_100k_classification_noise.csv\")\n",
    "target_name = \"Target\"\n",
    "y_train = df.pop(target_name)\n",
    "X_train = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/foxfo/OneDrive/Desktop/noir_ml/data/class_1milion_50features_multiclass.csv\")\n",
    "target_name = \"Target\"\n",
    "y_train = df.pop(target_name)\n",
    "X_train = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\foxfo\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver=\"adam\", \n",
    "                    max_iter=100, \n",
    "                    hidden_layer_sizes=(32,32,32),\n",
    "                      activation='relu', \n",
    "                      learning_rate_init=0.01,\n",
    "                      alpha=0,\n",
    "                      batch_size=10000,\n",
    "                      early_stopping=False, \n",
    "                      n_iter_no_change=100).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver=\"adam\", \n",
    "                    max_iter=1000, \n",
    "                    hidden_layer_sizes=(32,32,32),\n",
    "                      activation='relu', \n",
    "                      learning_rate_init=0.01,\n",
    "                      alpha=0,\n",
    "                      tol=1e-5,\n",
    "                      early_stopping=True,\n",
    "                      n_iter_no_change=20,\n",
    "                      batch_size=20000).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97092"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(32, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove gpu\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 6. 15.]\n",
      " [ 6. 15.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "a = tf.constant([[1.0,2.0,3.0],[1.0,2.0,3.0]])\n",
    "b = tf.constant([[1.0,.0],[1.0,3.0],[1.0,3.0]])\n",
    "c = tf.matmul(a,b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/class_100k_classification_noise.csv\")\n",
    "target_name = \"Target\"\n",
    "y_train = df.pop(target_name)\n",
    "X_train = df\n",
    "\n",
    "y_train = tfk.utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/class_100k_10features_classification.csv\")\n",
    "target_name = \"Target\"\n",
    "y_train = df.pop(target_name)\n",
    "X_train = df\n",
    "\n",
    "y_train = tfk.utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/class_100k_10features_classification.csv\")\n",
    "target_name = \"Target\"\n",
    "y_train = df.pop(target_name)\n",
    "X_train = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/foxfo/OneDrive/Desktop/noir_ml/data/class_1milion_50features_multiclass.csv\")\n",
    "target_name = \"Target\"\n",
    "y_train = df.pop(target_name)\n",
    "X_train = df\n",
    "\n",
    "y_train = tfk.utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20000\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ffnn(input_shape):\n",
    "\n",
    "    # Build the neural network layer by layer\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
    "    hidden_layer1 = tfkl.Dense(units=32, activation='relu', name='Hidden1')(input_layer)\n",
    "    hidden_layer2 = tfkl.Dense(units=32, activation='relu', name='Hidden2')(hidden_layer1)\n",
    "    hidden_layer3 = tfkl.Dense(units=32, activation='relu', name='Hidden3')(hidden_layer2)\n",
    "    output_layer = tfkl.Dense(units=8, activation='Softmax', name='Output')(hidden_layer3)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='FFNN')\n",
    "\n",
    "    # Compile the model\n",
    "    loss = tfk.losses.CategoricalCrossentropy()\n",
    "    learning_rate = 0.01\n",
    "    optimizer = tfk.optimizers.Adam(learning_rate)\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"FFNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 10)]              0         \n",
      "                                                                 \n",
      " Hidden1 (Dense)             (None, 32)                352       \n",
      "                                                                 \n",
      " Hidden2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " Hidden3 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " Output (Dense)              (None, 8)                 264       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,728\n",
      "Trainable params: 2,728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ffnn = build_ffnn(input_shape)\n",
    "ffnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = ffnn.fit(\n",
    "    x = X_train,\n",
    "    y = y_train, \n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs\n",
    ").history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "10/10 [==============================] - 1s 5ms/step - loss: 1.8904\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4953\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.2242\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0575\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9619\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8928\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8493\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8157\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7923\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7697\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7497\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7322\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7168\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7057\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6977\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6826\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6723\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6645\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6613\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6512\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6433\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6381\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6317\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6251\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6199\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6138\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6130\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6077\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6010\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5946\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5922\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5863\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5812\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5799\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5765\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5733\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5721\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5681\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5634\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5606\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5571\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5571\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5581\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5547\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5544\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5498\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5469\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5445\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5447\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5420\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5387\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5396\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5396\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5384\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5342\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5316\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5297\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5306\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5301\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5245\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5247\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5230\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5196\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5209\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5178\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5166\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5153\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5124\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5146\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5151\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5152\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5144\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5119\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5102\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5079\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5059\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5036\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5023\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4991\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4980\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4983\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4988\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4993\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4974\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4952\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4993\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4963\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4921\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4901\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4891\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4897\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4865\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4855\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4848\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4829\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4816\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4825\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4857\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4818\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4798\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4782\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4781\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4759\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4751\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4745\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4743\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4743\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4760\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4721\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4720\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4713\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4706\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4687\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4681\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4671\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4659\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4652\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4647\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4668\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4646\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4639\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4630\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4653\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4664\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4657\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4671\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4630\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4706\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4638\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4598\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4573\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4590\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4578\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4605\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4580\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4570\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4561\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4559\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4564\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4538\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4558\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4541\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4540\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4542\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4531\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4537\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4543\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4549\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4523\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4522\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4514\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4506\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4526\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4533\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4505\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4513\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4499\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4489\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4493\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4499\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4474\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4474\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4458\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4466\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4462\n",
      "Epoch 166/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4504\n",
      "Epoch 167/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4522\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4521\n"
     ]
    }
   ],
   "source": [
    "history = ffnn.fit(\n",
    "    x = X_train,\n",
    "    y = y_train, \n",
    "    batch_size = 10000,\n",
    "    callbacks = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss',\n",
    "    min_delta=1e-5,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=0\n",
    "),\n",
    "    epochs = epochs\n",
    ").history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/3125 [..............................] - ETA: 2:26"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 7s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = ffnn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85239"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(y_train, axis=-1), np.argmax(predictions, axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/housing_numeric.csv\")\n",
    "target_name = \"median_house_value\"\n",
    "y_train = df.pop(target_name)\n",
    "X_train = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Create an instance of StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df = pd.read_csv(\"data/housing_numeric.csv\")\n",
    "# Normalize the DataFrame\n",
    "normalized_data = scaler.fit_transform(df)\n",
    "\n",
    "# Convert the normalized data back to a DataFrame\n",
    "normalized_df = pd.DataFrame(normalized_data, columns=df.columns)\n",
    "\n",
    "y_train = normalized_df.pop(target_name)\n",
    "X_train = normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20640\n",
    "epochs = 1000\n",
    "input_shape = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ffnn(input_shape):\n",
    "\n",
    "    # Build the neural network layer by layer\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
    "    hidden_layer1 = tfkl.Dense(units=32, activation='relu', name='Hidden1')(input_layer)\n",
    "    hidden_layer2 = tfkl.Dense(units=32, activation='relu', name='Hidden2')(hidden_layer1)\n",
    "    hidden_layer3 = tfkl.Dense(units=32, activation='relu', name='Hidden3')(hidden_layer2)\n",
    "    output_layer = tfkl.Dense(units=1, activation=\"linear\", name='Output')(hidden_layer3)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='FFNN')\n",
    "\n",
    "    # Compile the model\n",
    "    loss = tfk.losses.MeanSquaredError()\n",
    "    learning_rate = 0.01\n",
    "    optimizer = tfk.optimizers.Adam(learning_rate)\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ffnn(input_shape):\n",
    "\n",
    "    # Build the neural network layer by layer\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
    "    hidden_layer1 = tfkl.Dense(units=132, activation='relu', name='Hidden1')(input_layer)\n",
    "    hidden_layer2 = tfkl.Dense(units=132, activation='relu', name='Hidden2')(hidden_layer1)\n",
    "    hidden_layer3 = tfkl.Dense(units=132, activation='relu', name='Hidden3')(hidden_layer2)\n",
    "    output_layer = tfkl.Dense(units=1, activation=\"linear\", name='Output')(hidden_layer3)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='FFNN')\n",
    "\n",
    "    # Compile the model\n",
    "    loss = tfk.losses.MeanSquaredError()\n",
    "    learning_rate = 0.01\n",
    "    optimizer = tfk.optimizers.Adam(learning_rate)\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"FFNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 10)]              0         \n",
      "                                                                 \n",
      " Hidden1 (Dense)             (None, 132)               1452      \n",
      "                                                                 \n",
      " Hidden2 (Dense)             (None, 132)               17556     \n",
      "                                                                 \n",
      " Hidden3 (Dense)             (None, 132)               17556     \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 133       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,697\n",
      "Trainable params: 36,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ffnn = build_ffnn(input_shape)\n",
    "ffnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 1s 16ms/step - loss: 6.4472\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.2362\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 3.7312\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 3.2402\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 2.9073\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 2.7327\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 2.5348\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 2.3691\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 2.2443\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.1729\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 2.1153\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.0990\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 2.0440\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.9791\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.9268\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.9156\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.0357\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.9304\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.8505\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.8201\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.7989\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.7709\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.7851\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.7427\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.7369\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.7885\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.8238\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.7148\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.6652\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.6617\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.6261\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.6211\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.6064\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.6169\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.5886\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.5500\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.5421\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.5620\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.5243\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.5219\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.5482\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.4986\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.4893\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.4596\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.5574\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.5272\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.4742\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.4624\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.4432\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.4207\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.4306\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.4150\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.4328\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.4123\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.3903\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.4054\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.3717\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.3582\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.3679\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.3531\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.3451\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.3441\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.3536\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.3592\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.3456\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.3178\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.3118\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.3047\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.3550\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.3303\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.3272\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.3050\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.3055\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2863\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2748\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2816\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2644\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.2732\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.2602\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2616\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2671\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2600\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2573\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.2492\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2424\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2327\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2500\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2323\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2464\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2485\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.2281\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.2367\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.2379\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.2192\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2671\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.2689\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2168\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 1.2069\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2008\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.1961\n"
     ]
    }
   ],
   "source": [
    "history = ffnn.fit(\n",
    "    x = X_train,\n",
    "    y = y_train, \n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs\n",
    ").history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 3s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = ffnn.predict(X_train)\n",
    "# sse = np.square(y_pred - np.array(y_train))\n",
    "# mse = np.mean(sse)\n",
    "# mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8899003923854711"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0977805 ],\n",
       "       [ 2.3102572 ],\n",
       "       [ 2.045048  ],\n",
       "       ...,\n",
       "       [-0.99545115],\n",
       "       [-0.9377994 ],\n",
       "       [-0.8071291 ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
